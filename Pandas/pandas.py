# -*- coding: utf-8 -*-
"""Pandas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ef3nkMKzjA2Vn1OZ3HQiWMiZ8B3JaQ06

# Pandas

Created by Wes McKInney, Pandas stands for Panel Data library

1. Series and DataFrames
2. Missing Data
3. GroupBy
4. Operations
5. Data I/O (Input and Output)

#Series

A series is the basic building block of Pandas.

It holds an array of information organized by an Index.
A lot look like a NumPy array.

The differentiating factor between a NumPy array and Pandas
Series is that a Series can have a named index,
So it will still remember and recall information based
off a numerical index, like 01,2,3 etc but it has a named
index that then you can call data directly off that named
index.

This is really very helpful in general because people think
better in terms of categories and names than just some random
integer for the index.

So it's gonna be a lot easier for us to kind of query our data
and ask, hey what is the data point for Chicago?
data points stands for population.
"""

import numpy as np
import pandas as pd

labels=["a","b","c"]
print(labels)

print(" ")

myls=[10,20,30]
print(myls)

arr=np.array(myls)
arr

d= { "a":10,"b":20,"c":30}
d

pd.Series(data=myls)

pd.Series(arr)

pd.Series(data=arr,index=labels)

# Now we can see our Series has named index.

pd.Series(data=[10,"a",4.4])

# it will not be able to store everything as same datatype
# so it will store as an object.

series_1=pd.Series([1,2,3,4],index=["India","USA","Russia","Japan"])
series_1

series_1["India"]

series_2=pd.Series([1,4,5,6],index=["India","USA","Russia","UK"])
series_2

series_1+series_2

"""# DataFrames

A DataFrame is simply multiple series that share the same index!

it is essentially a tablular data storage format.
"""

import pandas as pd
import numpy as np

from numpy.random import randn
np.random.seed(101)

rand_matrix=randn(5,4)
rand_matrix

pd.DataFrame(rand_matrix)

df=pd.DataFrame(data=rand_matrix)
df

df=pd.DataFrame(data=rand_matrix,index="A B C D E".split())
df

df=pd.DataFrame(data=rand_matrix,index="A B C D E".split(),
                columns="W X Y Z".split())
df

# single column
df["W"]

type(df["W"])

# each of these individual column is a series which is why
# formatting changes.

#multiple columns

myls=["W","Y"]
df[myls]

df[["W","Y"]]

# A list pass in square brackets to get those columns

df.W

# this is not recommended because dataframe has a lot of
# methods and attributes in them.
# when we try to get column like this
# it will confuse pandas by calling column name that
# happens to have the same name as one of these methods/variable.

# Create a new column

df["New_Column"]=df["W"]+df["Y"]
df

# Remove a column

# df.drop("New_Column")

#KeyError: "['New_Column'] not found in axis"

# this will give a KeyError.
# whenever we get KeyError with DataFrames and Pandas, that's
# basically tells , either passing in the wrong axes or you
# passing in the wrong name
# axis=1 to drop column and axis=0 to drop row.

df.drop("New_Column",axis=1)

df

# New_Column is still there in dataframe.

# if we want to permenantely delete column that we use
# inplace=True
# default is inplace+False.
# so we have to add this if we want to remove column.

df.drop("New_Column",axis=1,inplace=True)
df

# Remove Column

df.drop("A")

df

# if we want to remove row permenantly we need to specify
# inplace= True

# Select rows

# using loc:- Specify name

#  or iloc:- Specify index location

df.loc["A"]

df.iloc[0]

df.iloc[2]

df.loc["C"]

# select multiple rows using loc

df.loc[["A","E"]]

# select multiple rows using iloc

df.iloc[[0,4]]

# grabs particular values from rows and columns

df.loc[["A","B"],["Y","Z"]]

# grabs particular values from rows and columns
# using iloc

df.iloc[[0,1],[2,3]]

"""# DataFrames Continue...

**Conditional Selection**
"""

df>0

df_bool=df[df>0]
df_bool

df[df>0]

df["W"]>0

df[df["W"]>0]

df[df["W"]>0]["W"]

df[df["W"]>0]["W"].loc["A"]

# individual value

# two conditions

condition_1=df["W"]>0

condition_2=df["Y"]>1

#df[condition_1 and condition_2]

# this will give a
# ValueError: The truth value of a Series is ambiguous.
# Use a.empty, a.bool(), a.item(), a.any() or a.all().

# because keyword AND/OR are not designed for Series.
# condition_1 is the entire series of boolean values.
# Python AND/OR operations are not designed for that.
# They are just designed to compare 1 boolean to another.

# SO for Pandas we use &(AND) and |(OR) operator with ()

df[(condition_1) & (condition_2)]

df[ (df["W"]<0 & (df["Z"]>0))]

df

# reset index
df.reset_index()

# we can use inplace=True to permnenantly changes rows name

df

new_ind="Guj Raj MP UP MH".split()
new_ind

df["States"]=new_ind
df

# set a states column as an Index
# meaning states names as rows.

df.set_index("States")

# we can use inplace=True to permnenantly changes rows name

df.info()

df.dtypes

df.describe()

# columns with string values will not be shown here
# it work only on numerical data.

df

df["W"]>0

# how many are true and false

series_w=df["W"]>0

series_w.value_counts()

sum(series_w)

len(series_w)

"""# Group By Operations

Often you may want to perform an analysis based off the value
of a specific column, meaning you want to group together other
columns based off another

In order to do this, we have  to perform 3 steps

Group By Operations involve:
1. Split
2. Apply
3. Combine

Pandas does all of this for with a simple method
call:- groupby()

Pandas will automatically make the grouped by column the
index of the new resulting DataFrame
"""

import pandas as pd

data={
    "Company":["GOOG","GOOG","MSFT","MSFT","FB","FB"],
    "Person":["Malav","Mrugesh","Maya","Minaxi","Gopi","Madhvi"],
    "Sales":[200,120,340,124,243,350]
}
data

df=pd.DataFrame(data)
df

df.groupby("Company")

# it did not show anything because we need to perform
# aggregate function with grouby method.
# it is waiting for you tell it how you actually want to
# combine or aggregate

df.groupby("Company")["Sales"].mean()

df.groupby("Company")["Sales"].min()

df.groupby("Company")["Sales"].max()

df.groupby("Company")["Sales"].std()

df.groupby("Company").describe()

df.groupby("Company").describe().transpose()

"""# Pandas Operations"""

import pandas as pd

data={
    "col1":[1,2,3,4],
    "col2":[444,555,666,444],
    "col3":["abc","def","ghi","xyz"]
}
data

df=pd.DataFrame(data)
df

df["col2"].unique()

df["col2"].nunique()

#total unique values

df["col2"].value_counts()

# col1 >2
# col2 == 444

newdf=df[(df['col1']>2)  & (df['col2']==444)]
newdf

# Apply function to every value in a column

def times_two(number):

    return number*2

times_two(2)

df

df['new']=df['col1'].apply(times_two)
df

# permenantely remove column
del df['new']
df

df.columns

df.index

df.info()

df.describe()

df

# sort by col2

df.sort_values(by='col2')

# sort by col2

df.sort_values(by='col2',ascending=False)

"""# Data Input and Output"""

import numpy as np
import pandas as pd

"""## CSV
Comma Separated Values files are text files that use commas as field delimeters.<br>
Unless you're running the virtual environment included with the course, you may need to install <tt>xlrd</tt> and <tt>openpyxl</tt>.<br>
In your terminal/command prompt run:

    conda install xlrd
    conda install openpyxl

Then restart Jupyter Notebook.
(or use pip install if you aren't using the Anaconda Distribution)

### CSV Input
"""

pwd

df=pd.read_csv("example.csv")
df

"""#CSV Output"""

df.to_csv("example.csv",index=False)

"""## Excel
Pandas can read and write MS Excel files. However, this only imports data, not formulas or images. A file that contains images or macros may cause the <tt>.read_excel()</tt>method to crash.
"""

df=pd.read_excel('Excel_Sample.xlsx',sheet_name='Sheet1')
df

df.columns

df.drop("Unnamed: 0",axis=1,inplace=True)
df

df.to_excel('Excel_Sample.xlsx',sheet_name='Sheet1')

"""## HTML
Pandas can read table tabs off of HTML.<br>
Unless you're running the virtual environment included with the course, you may need to install <tt>lxml</tt>, <tt>htmllib5</tt>, and <tt>BeautifulSoup4</tt>.<br>
In your terminal/command prompt run:

    conda install lxml
    conda install html5lib
    conda install beautifulsoup4

Then restart Jupyter Notebook.
(or use pip install if you aren't using the Anaconda Distribution)

### HTML Input

Pandas read_html function will read tables off of a webpage and return a list of DataFrame objects:
"""

df = pd.read_html('http://www.fdic.gov/bank/individual/failed/banklist.html')

df[0].head()